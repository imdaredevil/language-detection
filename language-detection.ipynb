{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2e771c7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T13:51:45.881131Z",
     "start_time": "2021-07-22T13:51:45.868778Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import gc\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras import Sequential \n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f13823ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:32.071253Z",
     "start_time": "2021-07-22T12:26:19.673523Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/sentences.csv', sep='\\t', \n",
    "                            encoding='utf8', \n",
    "                            index_col=0,\n",
    "                            names=['lang','text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e897eff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:32.145332Z",
     "start_time": "2021-07-22T12:26:32.142418Z"
    }
   },
   "outputs": [],
   "source": [
    "LanguageList = ['eng','fra', 'spa','ita','deu']\n",
    "ngramLength = 3\n",
    "maxFeatures = 500\n",
    "sentencePerLanguageForVocab = 1000\n",
    "sentencePerLanguageForDataSet = 50000\n",
    "validationSentences = 25000\n",
    "testSentences = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "731954c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:36.550175Z",
     "start_time": "2021-07-22T12:26:32.902053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250000</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>deu</td>\n",
       "      <td>È la ragazza perfetta per lei.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lang                            text\n",
       "count   250000                          250000\n",
       "unique       5                          250000\n",
       "top        deu  È la ragazza perfetta per lei.\n",
       "freq     50000                               1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtereddf = pd.DataFrame(columns=df.columns)\n",
    "for l in LanguageList:\n",
    "    filtereddf = pd.concat([filtereddf, \n",
    "                            df[df['lang'] == l].sample(\n",
    "                                sentencePerLanguageForDataSet)])\n",
    "\n",
    "filtereddf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d87f7133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:37.076373Z",
     "start_time": "2021-07-22T12:26:36.651322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ita</td>\n",
       "      <td>È la ragazza perfetta per lei.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>40070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          lang                            text\n",
       "count   200000                          200000\n",
       "unique       5                          200000\n",
       "top        ita  È la ragazza perfetta per lei.\n",
       "freq     40070                               1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtereddf = filtereddf.sample(frac=1)\n",
    "validation_df = filtereddf[:validationSentences]\n",
    "test_df = filtereddf[validationSentences:validationSentences + testSentences]\n",
    "train_df = filtereddf[validationSentences + testSentences :]\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809876df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:37.549671Z",
     "start_time": "2021-07-22T12:26:37.239363Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df,filtereddf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a751eb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:37.709764Z",
     "start_time": "2021-07-22T12:26:37.654172Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_vectors(dataset):\n",
    "    vectorizer = CountVectorizer(analyzer='char',ngram_range=(ngramLength,ngramLength),max_features=maxFeatures)\n",
    "    vectorizer.fit_transform(dataset)\n",
    "    trigrams = vectorizer.get_feature_names()\n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0850b4b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:42.335892Z",
     "start_time": "2021-07-22T12:26:42.057524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for l in LanguageList:\n",
    "    currData = train_df[train_df['lang'] == l].sample(sentencePerLanguageForVocab)\n",
    "    currFeatures = get_feature_vectors(currData['text'].to_list())\n",
    "    vocab.update(currFeatures)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dea19b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:47.202968Z",
     "start_time": "2021-07-22T12:26:47.190192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectorizer = CountVectorizer(analyzer='char',ngram_range=(ngramLength,ngramLength), vocabulary=vocab)\n",
    "feature_names = word_vectorizer.get_feature_names()\n",
    "langEncoder = LabelEncoder()\n",
    "langEncoder.fit(LanguageList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a90f570d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:54.479497Z",
     "start_time": "2021-07-22T12:26:50.199047Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = word_vectorizer.transform(train_df['text'].to_list())\n",
    "min_value = train_x.min(axis=0).toarray()\n",
    "min_df = pd.Series(min_value[0], index=feature_names)\n",
    "max_value = train_x.max(axis=0).toarray()\n",
    "max_df = pd.Series(max_value[0], index=feature_names)\n",
    "del max_value,min_value,train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "422b4853",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:26:54.644982Z",
     "start_time": "2021-07-22T12:26:54.637862Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_generator(dataset, batch_size):\n",
    "    noOfBatches = len(dataset)//batch_size\n",
    "    batches = np.array_split(dataset,noOfBatches)\n",
    "    i = 0\n",
    "    while True:\n",
    "        batch = batches[i]\n",
    "        i += 1\n",
    "        if i == noOfBatches:\n",
    "            i = 0\n",
    "        # getting x\n",
    "        x = word_vectorizer.transform(batch['text'].to_list())\n",
    "        xdf = pd.DataFrame(data=x.toarray(), columns=feature_names)\n",
    "        xdf = (xdf - min_df)/(max_df - min_df)\n",
    "        x_num = xdf.to_numpy()\n",
    "    \n",
    "        # getting y\n",
    "        y = batch['lang'].to_list()\n",
    "        y_enc = langEncoder.transform(y)\n",
    "        y_num = to_categorical(y_enc, num_classes=len(LanguageList))\n",
    "        yield x_num,y_num    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c5a42f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:27:01.031019Z",
     "start_time": "2021-07-22T12:26:56.310809Z"
    }
   },
   "outputs": [],
   "source": [
    "# testing generator\n",
    "gen = iter(data_generator(train_df,3))\n",
    "tempx, tempy = next(gen)\n",
    "tempx.shape\n",
    "tempy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "989dc31a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:27:01.438832Z",
     "start_time": "2021-07-22T12:27:01.436317Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c831d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:27:04.817286Z",
     "start_time": "2021-07-22T12:27:04.807024Z"
    }
   },
   "outputs": [],
   "source": [
    "train_generator = data_generator(train_df, batch_size)\n",
    "val_generator = data_generator(validation_df, batch_size)\n",
    "test_generator = data_generator(test_df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8f0383f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:27:06.267799Z",
     "start_time": "2021-07-22T12:27:06.254580Z"
    }
   },
   "outputs": [],
   "source": [
    "train_steps_per_epoch = len(train_df)//batch_size\n",
    "val_steps_per_epoch = len(validation_df)//batch_size\n",
    "test_steps_per_epoch = len(test_df)//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ca66b73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:27:08.672954Z",
     "start_time": "2021-07-22T12:27:08.171108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               374784    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 408,325\n",
      "Trainable params: 408,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-22 17:57:08.192221: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-22 17:57:08.635031: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-07-22 17:57:08.635067: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ninjabox): /proc/driver/nvidia/version does not exist\n",
      "2021-07-22 17:57:08.636279: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256,input_dim=len(vocab), activation='relu'))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(len(LanguageList), activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "899525b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T12:27:13.392761Z",
     "start_time": "2021-07-22T12:27:13.363997Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7370bf7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T13:25:42.426020Z",
     "start_time": "2021-07-22T12:27:15.788707Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imdaredevil/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n",
      "2021-07-22 17:57:18.670730: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-07-22 17:57:18.690288: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2699905000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "40000/40000 [==============================] - 873s 22ms/step - loss: 0.0772 - accuracy: 0.9752 - val_loss: 0.0310 - val_accuracy: 0.9902\n",
      "Epoch 2/4\n",
      "40000/40000 [==============================] - 889s 22ms/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.0319 - val_accuracy: 0.9906\n",
      "Epoch 3/4\n",
      "40000/40000 [==============================] - 871s 22ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.0455 - val_accuracy: 0.9906\n",
      "Epoch 4/4\n",
      "40000/40000 [==============================] - 870s 22ms/step - loss: 0.0116 - accuracy: 0.9964 - val_loss: 0.0587 - val_accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5d1b41b80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,\n",
    "          steps_per_epoch=train_steps_per_epoch,\n",
    "          validation_data=val_generator,\n",
    "          validation_steps=val_steps_per_epoch,\n",
    "          epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59f42fdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T13:39:12.128304Z",
     "start_time": "2021-07-22T13:39:11.501084Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./models/basic-model-2.model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./models/basic-model-2.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ded34a49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T13:32:11.055707Z",
     "start_time": "2021-07-22T13:32:10.792114Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imdaredevil/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py:3703: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable.debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spa\n"
     ]
    }
   ],
   "source": [
    "sentence = 'Buenos dias'\n",
    "man_test_x = word_vectorizer.transform([sentence])\n",
    "man_test_df = pd.DataFrame(data=man_test_x.toarray(), columns=word_vectorizer.get_feature_names())\n",
    "man_test_df = (man_test_df - min_df)/(max_df - min_df)\n",
    "man_test_num = man_test_df.to_numpy()\n",
    "y = model.predict(man_test_num)\n",
    "label = np.argmax(y)\n",
    "prediction = langEncoder.inverse_transform([label])\n",
    "prediction = prediction[0]\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05b77630",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-22T13:40:00.621059Z",
     "start_time": "2021-07-22T13:40:00.604554Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "preprocessing_objects = {\n",
    "    'word_vectorizer': word_vectorizer,\n",
    "    'lang_encoder': langEncoder,\n",
    "    'min_df': min_df,\n",
    "    'max_df': max_df\n",
    "}\n",
    "pickle.dump(preprocessing_objects,open('./models/basic-model-2-preprocessing-objects.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
